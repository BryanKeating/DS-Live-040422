{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Objectives\" data-toc-modified-id=\"Objectives-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Objectives</a></span></li><li><span><a href=\"#Motivation\" data-toc-modified-id=\"Motivation-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Motivation</a></span></li><li><span><a href=\"#Scenario:-Identifying-Fraudulent-Credit-Card-Transactions\" data-toc-modified-id=\"Scenario:-Identifying-Fraudulent-Credit-Card-Transactions-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Scenario: Identifying Fraudulent Credit Card Transactions</a></span><ul class=\"toc-item\"><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>EDA</a></span></li><li><span><a href=\"#Logistic-Regression\" data-toc-modified-id=\"Logistic-Regression-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Logistic Regression</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Evaluation</a></span></li><li><span><a href=\"#Confusion-Matrix\" data-toc-modified-id=\"Confusion-Matrix-3.4\"><span class=\"toc-item-num\">3.4&nbsp;&nbsp;</span>Confusion Matrix</a></span></li><li><span><a href=\"#Classification-Metrics\" data-toc-modified-id=\"Classification-Metrics-3.5\"><span class=\"toc-item-num\">3.5&nbsp;&nbsp;</span>Classification Metrics</a></span></li><li><span><a href=\"#Accuracy\" data-toc-modified-id=\"Accuracy-3.6\"><span class=\"toc-item-num\">3.6&nbsp;&nbsp;</span>Accuracy</a></span></li><li><span><a href=\"#Recall\" data-toc-modified-id=\"Recall-3.7\"><span class=\"toc-item-num\">3.7&nbsp;&nbsp;</span>Recall</a></span></li><li><span><a href=\"#Precision\" data-toc-modified-id=\"Precision-3.8\"><span class=\"toc-item-num\">3.8&nbsp;&nbsp;</span>Precision</a></span></li><li><span><a href=\"#$F$-Scores\" data-toc-modified-id=\"$F$-Scores-3.9\"><span class=\"toc-item-num\">3.9&nbsp;&nbsp;</span>$F$-Scores</a></span></li><li><span><a href=\"#classification_report()\" data-toc-modified-id=\"classification_report()-3.10\"><span class=\"toc-item-num\">3.10&nbsp;&nbsp;</span><code>classification_report()</code></a></span></li></ul></li><li><span><a href=\"#Exercise:-Breast-Cancer-Prediction\" data-toc-modified-id=\"Exercise:-Breast-Cancer-Prediction-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Exercise: Breast Cancer Prediction</a></span><ul class=\"toc-item\"><li><span><a href=\"#Task\" data-toc-modified-id=\"Task-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Task</a></span></li></ul></li><li><span><a href=\"#Multiclass-Classification\" data-toc-modified-id=\"Multiclass-Classification-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Multiclass Classification</a></span></li><li><span><a href=\"#Summary:-Which-Metric-Should-I-Care-About?\" data-toc-modified-id=\"Summary:-Which-Metric-Should-I-Care-About?-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Summary: Which Metric Should I Care About?</a></span></li><li><span><a href=\"#Level-Up:-Cost-Matrix\" data-toc-modified-id=\"Level-Up:-Cost-Matrix-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Level Up: Cost Matrix</a></span></li><li><span><a href=\"#Level-Up:-Multiclass-Example\" data-toc-modified-id=\"Level-Up:-Multiclass-Example-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Level Up: Multiclass Example</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.datasets import load_breast_cancer, load_iris, make_classification\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix,\\\n",
    "    precision_score, recall_score, accuracy_score, f1_score, log_loss,\\\n",
    "    roc_curve, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Objectives"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "- Calculate and interpret a confusion matrix\n",
    "- Calculate and interpret classification metrics such as accuracy, recall, and precision\n",
    "- Choose classification metrics appropriate to a business problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "There are many ways to evaluate a classification model, and your choice of evaluation metric can have a major impact on how well your model serves its intended goals. This lecture will review common classification metrics you might consider using, and considerations for how to make your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Scenario: Identifying Fraudulent Credit Card Transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Credit card companies often try to identify whether a transaction is fraudulent at the time when it occurs, in order to decide whether to approve it. Let's build a classification model to try to classify fraudulent transactions! \n",
    "\n",
    "The data for this example from from [this Kaggle dataset](https://www.kaggle.com/mlg-ulb/creditcardfraud)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Code to downsample from original dataset\n",
    "#\n",
    "# credit_data = pd.read_csv('creditcard.csv')\n",
    "# credit_data_small = credit_data.iloc[0:10000]\n",
    "# credit_data_small.describe()\n",
    "# credit_data_small.to_csv('credit_fraud_small.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "credit_data = pd.read_csv('data/credit_fraud_small.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The dataset contains features for the transaction amount, the relative time of the transaction, and 28 other features formed using PCA. The target 'Class' is a 1 if the transaction was fraudulent, 0 otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.0</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0   0.0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1   0.0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2   1.0 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3   1.0 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4   2.0 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      0  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's see what we can learn from some summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.000000</td>\n",
       "      <td>10000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5966.033400</td>\n",
       "      <td>-0.241862</td>\n",
       "      <td>0.281949</td>\n",
       "      <td>0.906270</td>\n",
       "      <td>0.264148</td>\n",
       "      <td>-0.046398</td>\n",
       "      <td>0.133108</td>\n",
       "      <td>-0.071689</td>\n",
       "      <td>-0.064778</td>\n",
       "      <td>0.802224</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.051990</td>\n",
       "      <td>-0.152671</td>\n",
       "      <td>-0.033268</td>\n",
       "      <td>0.021335</td>\n",
       "      <td>0.087146</td>\n",
       "      <td>0.108140</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>63.030188</td>\n",
       "      <td>0.00380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4473.403739</td>\n",
       "      <td>1.521679</td>\n",
       "      <td>1.308139</td>\n",
       "      <td>1.159154</td>\n",
       "      <td>1.441235</td>\n",
       "      <td>1.182935</td>\n",
       "      <td>1.307311</td>\n",
       "      <td>1.077430</td>\n",
       "      <td>1.259064</td>\n",
       "      <td>1.155198</td>\n",
       "      <td>...</td>\n",
       "      <td>0.913811</td>\n",
       "      <td>0.631083</td>\n",
       "      <td>0.487814</td>\n",
       "      <td>0.594430</td>\n",
       "      <td>0.428171</td>\n",
       "      <td>0.562793</td>\n",
       "      <td>0.410868</td>\n",
       "      <td>0.266247</td>\n",
       "      <td>184.486158</td>\n",
       "      <td>0.06153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>-27.670569</td>\n",
       "      <td>-34.607649</td>\n",
       "      <td>-15.496222</td>\n",
       "      <td>-4.657545</td>\n",
       "      <td>-32.092129</td>\n",
       "      <td>-23.496714</td>\n",
       "      <td>-26.548144</td>\n",
       "      <td>-23.632502</td>\n",
       "      <td>-6.329801</td>\n",
       "      <td>...</td>\n",
       "      <td>-11.468435</td>\n",
       "      <td>-8.527145</td>\n",
       "      <td>-15.144340</td>\n",
       "      <td>-2.512377</td>\n",
       "      <td>-2.577363</td>\n",
       "      <td>-1.338556</td>\n",
       "      <td>-7.976100</td>\n",
       "      <td>-3.509250</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2072.750000</td>\n",
       "      <td>-1.013283</td>\n",
       "      <td>-0.208342</td>\n",
       "      <td>0.412799</td>\n",
       "      <td>-0.614424</td>\n",
       "      <td>-0.643390</td>\n",
       "      <td>-0.629934</td>\n",
       "      <td>-0.542336</td>\n",
       "      <td>-0.190747</td>\n",
       "      <td>0.070868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.268120</td>\n",
       "      <td>-0.549638</td>\n",
       "      <td>-0.174120</td>\n",
       "      <td>-0.327817</td>\n",
       "      <td>-0.158137</td>\n",
       "      <td>-0.327974</td>\n",
       "      <td>-0.084489</td>\n",
       "      <td>-0.015753</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4563.500000</td>\n",
       "      <td>-0.372799</td>\n",
       "      <td>0.288524</td>\n",
       "      <td>0.944361</td>\n",
       "      <td>0.219861</td>\n",
       "      <td>-0.152769</td>\n",
       "      <td>-0.152566</td>\n",
       "      <td>-0.055585</td>\n",
       "      <td>0.012865</td>\n",
       "      <td>0.805275</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123273</td>\n",
       "      <td>-0.136746</td>\n",
       "      <td>-0.045794</td>\n",
       "      <td>0.079976</td>\n",
       "      <td>0.121001</td>\n",
       "      <td>0.042865</td>\n",
       "      <td>-0.004568</td>\n",
       "      <td>0.015897</td>\n",
       "      <td>15.950000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>10233.250000</td>\n",
       "      <td>1.150864</td>\n",
       "      <td>0.901879</td>\n",
       "      <td>1.602903</td>\n",
       "      <td>1.125666</td>\n",
       "      <td>0.371081</td>\n",
       "      <td>0.505357</td>\n",
       "      <td>0.476280</td>\n",
       "      <td>0.274533</td>\n",
       "      <td>1.506299</td>\n",
       "      <td>...</td>\n",
       "      <td>0.032707</td>\n",
       "      <td>0.247490</td>\n",
       "      <td>0.081665</td>\n",
       "      <td>0.410877</td>\n",
       "      <td>0.359058</td>\n",
       "      <td>0.476394</td>\n",
       "      <td>0.120811</td>\n",
       "      <td>0.077182</td>\n",
       "      <td>50.960000</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>15012.000000</td>\n",
       "      <td>1.960497</td>\n",
       "      <td>8.636214</td>\n",
       "      <td>4.101716</td>\n",
       "      <td>10.463020</td>\n",
       "      <td>34.099309</td>\n",
       "      <td>21.393069</td>\n",
       "      <td>34.303177</td>\n",
       "      <td>5.060381</td>\n",
       "      <td>10.392889</td>\n",
       "      <td>...</td>\n",
       "      <td>22.588989</td>\n",
       "      <td>4.534454</td>\n",
       "      <td>13.876221</td>\n",
       "      <td>3.200201</td>\n",
       "      <td>5.525093</td>\n",
       "      <td>3.517346</td>\n",
       "      <td>8.254376</td>\n",
       "      <td>4.860769</td>\n",
       "      <td>7712.430000</td>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               Time            V1            V2            V3            V4  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean    5966.033400     -0.241862      0.281949      0.906270      0.264148   \n",
       "std     4473.403739      1.521679      1.308139      1.159154      1.441235   \n",
       "min        0.000000    -27.670569    -34.607649    -15.496222     -4.657545   \n",
       "25%     2072.750000     -1.013283     -0.208342      0.412799     -0.614424   \n",
       "50%     4563.500000     -0.372799      0.288524      0.944361      0.219861   \n",
       "75%    10233.250000      1.150864      0.901879      1.602903      1.125666   \n",
       "max    15012.000000      1.960497      8.636214      4.101716     10.463020   \n",
       "\n",
       "                 V5            V6            V7            V8            V9  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean      -0.046398      0.133108     -0.071689     -0.064778      0.802224   \n",
       "std        1.182935      1.307311      1.077430      1.259064      1.155198   \n",
       "min      -32.092129    -23.496714    -26.548144    -23.632502     -6.329801   \n",
       "25%       -0.643390     -0.629934     -0.542336     -0.190747      0.070868   \n",
       "50%       -0.152769     -0.152566     -0.055585      0.012865      0.805275   \n",
       "75%        0.371081      0.505357      0.476280      0.274533      1.506299   \n",
       "max       34.099309     21.393069     34.303177      5.060381     10.392889   \n",
       "\n",
       "       ...           V21           V22           V23           V24  \\\n",
       "count  ...  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean   ...     -0.051990     -0.152671     -0.033268      0.021335   \n",
       "std    ...      0.913811      0.631083      0.487814      0.594430   \n",
       "min    ...    -11.468435     -8.527145    -15.144340     -2.512377   \n",
       "25%    ...     -0.268120     -0.549638     -0.174120     -0.327817   \n",
       "50%    ...     -0.123273     -0.136746     -0.045794      0.079976   \n",
       "75%    ...      0.032707      0.247490      0.081665      0.410877   \n",
       "max    ...     22.588989      4.534454     13.876221      3.200201   \n",
       "\n",
       "                V25           V26           V27           V28        Amount  \\\n",
       "count  10000.000000  10000.000000  10000.000000  10000.000000  10000.000000   \n",
       "mean       0.087146      0.108140      0.005518      0.002915     63.030188   \n",
       "std        0.428171      0.562793      0.410868      0.266247    184.486158   \n",
       "min       -2.577363     -1.338556     -7.976100     -3.509250      0.000000   \n",
       "25%       -0.158137     -0.327974     -0.084489     -0.015753      5.000000   \n",
       "50%        0.121001      0.042865     -0.004568      0.015897     15.950000   \n",
       "75%        0.359058      0.476394      0.120811      0.077182     50.960000   \n",
       "max        5.525093      3.517346      8.254376      4.860769   7712.430000   \n",
       "\n",
       "             Class  \n",
       "count  10000.00000  \n",
       "mean       0.00380  \n",
       "std        0.06153  \n",
       "min        0.00000  \n",
       "25%        0.00000  \n",
       "50%        0.00000  \n",
       "75%        0.00000  \n",
       "max        1.00000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    9962\n",
       "1      38\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "credit_data[\"Class\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider here - issues with train/test split - could have very few positive (fraudulent tests in it) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question**: What can we learn from the mean of the target 'Class'?\n",
    "\n",
    "<details>\n",
    "<summary>Answer</summary>\n",
    "Fraudulent transactions are rare - only 0.4% of transactions were fraudulent\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's run a logistic regression model using all of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=42)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate data into feature and target DataFrames\n",
    "X = credit_data.drop('Class', axis = 1)\n",
    "y = credit_data['Class']\n",
    "\n",
    "# Split data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.25,\n",
    "                                                   random_state=1)\n",
    "# Scale the data for modeling\n",
    "cred_scaler = StandardScaler()\n",
    "cred_scaler.fit(X_train)#\n",
    "X_train_sc = cred_scaler.transform(X_train)#\n",
    "X_test_sc = cred_scaler.transform(X_test)#\n",
    "\n",
    "\n",
    "#these three lines above, could be combined into the two lines below \n",
    "#X_train_sc = cred_scaler.fit_transform(X_train)\n",
    "# X_test_sc = cred_scaler.transform(X_Test)\n",
    "\n",
    "#just pick one of the methods and stick to it!!! \n",
    "\n",
    "# Train a logistic regresssion model with the train data\n",
    "cred_model = LogisticRegression(random_state=42)\n",
    "cred_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7469\n",
       "1      31\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scilearn in python - log reg - by default it regualrizes our model (by ridge) so we need to make sure we \n",
    "#standard scale it first!!!! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's calculate the accuracy score for our model using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cred_model.score(X_test_sc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We got 99.88% accuracy, meaning that 99.88% of our predictions were correct! That seems great, right? Maybe... too great? Let's dig in deeper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nope- bc our dataset is inbalanced ---- DO NOT USE ACCURACY!! Must use a different method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Confusion Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's consider the four categories of predictions our model might have made:\n",
    "\n",
    "* Predicting that a transaction was fraudulent when it actually was (**true positive** or **TP**)\n",
    "* Predicting that a transaction was fraudulent when it actually wasn't (**false positive** or **FP**)\n",
    "* Predicting that a transaction wasn't fraudulent when it actually was (**false negative** or **FN**)\n",
    "* Predicting that a transaction wasn't fraudulent when it actually wasn't (**true negative** or **TN**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "<img src='../images/precisionrecall.png' width=70%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The **confusion matrix** gives us all four of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2493,    0],\n",
       "       [   3,    4]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = cred_model.predict(X_test_sc)\n",
    "cm_1 = confusion_matrix(y_test, y_pred)\n",
    "cm_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dont use the box above, just rememebr the one below!!! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryankeating/miniconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# More visual representation\n",
    "plot_confusion_matrix(cred_model, X_test_sc, y_test);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Notice the way that sklearn displays its confusion matrix: The rows are \\['actually false', 'actually true'\\]; the columns are \\['predicted false', 'predicted true'\\].\n",
    "\n",
    "So it displays:\n",
    "\n",
    "$\\begin{bmatrix}\n",
    "TN & FP \\\\\n",
    "FN & TP\n",
    "\\end{bmatrix}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lots of (TN)true negatives (not shocking)\n",
    "#0 FP - False Positive \n",
    "#False Negative - 3 of them - missed 3 - 3 slipped through the cracks \n",
    "# 4 True Negatives TN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Do you see anything surprising in the confusion matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#below is just for practive "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn = 44\n",
    "fp = 53\n",
    "fn = 18\n",
    "tp = 500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8845528455284553\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9652509652509652\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9041591320072333\n"
     ]
    }
   ],
   "source": [
    "prec = tp / (tp + fp)\n",
    "print(prec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Classification Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's calculate some common classification metrics and consider which would be most useful for this scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "tn = 2493\n",
    "fp = cm_1[0, 1]\n",
    "fn = cm_1[1, 0]\n",
    "tp = cm_1[1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#above just instatiating variables - using indexing "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Accuracy** = $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "In words: How often did my model correctly identify transactions (fraudulent or not fraudulent)? This should give us the same value as we got from the `.score()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9988\n"
     ]
    }
   ],
   "source": [
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accuracy is defalt for .score "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Recall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Recall** = **Sensitivity** = $\\frac{TP}{TP + FN}$\n",
    "\n",
    "In words: How many of the actually fraudulent transactions did my model identify? \n",
    "**A model that produces no false negatives has a recall of 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5714285714285714\n"
     ]
    }
   ],
   "source": [
    "rec = tp / (tp + fn)\n",
    "print(rec)\n",
    "\n",
    "#57%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this means that i fit some of your transactions were fraud when ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Do you think a credit card company would consider recall to be an important metric? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Precision** = $\\frac{TP}{TP + FP}$\n",
    "\n",
    "In words: How often was my model's prediction of 'fraudulent' correct?\n",
    "**A model that produces no false positives will have a precision of 1.0**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n"
     ]
    }
   ],
   "source": [
    "prec = tp / (tp + fp)\n",
    "print(prec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#because we didnt have any false positives "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Do you think a credit card company would care more about recall or precision?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## $F$-Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#higher F1 score is better - what we use when client says they care about both  FP and FN "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The $F$-score is a combination of precision and recall, which can be useful when both are important for a business problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most common is the **$F_1$ Score**, which is an equal balance of the two using a [harmonic mean](https://en.wikipedia.org/wiki/Harmonic_mean).\n",
    "\n",
    "$$F_1 = 2 \\frac{Pr \\cdot Rc}{Pr + Rc} = \\frac{2TP}{2TP + FP + FN}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "> _Recall a ***score** typically means higher is better_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7272727272727273\n"
     ]
    }
   ],
   "source": [
    "f1_score = 2*prec*rec / (prec + rec)\n",
    "print(f1_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "**Question:** Which of these metrics do you think a credit card company would care most about when trying to flag fraudulent transactions to deny?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "We can generalize this score to the **$F_\\beta$ Score** where increasing $\\beta$ puts more importance on _recall_:\n",
    "\n",
    "$$F_\\beta =  \\frac{(1+\\beta^2) \\cdot Precision \\cdot Recall}{\\beta^2 \\cdot Precision + Recall}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## `classification_report()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "You can get all of these metrics using the `classification_report()` function. \n",
    "\n",
    "- The top rows show statistics for if you treated each label as the \"positive\" class\n",
    "- **Support** shows the sample size in each class\n",
    "- The averages in the bottom two rows are across the rows in the class table above (useful when there are more than two classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      2493\n",
      "           1       1.00      0.57      0.73         7\n",
      "\n",
      "    accuracy                           1.00      2500\n",
      "   macro avg       1.00      0.79      0.86      2500\n",
      "weighted avg       1.00      1.00      1.00      2500\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Exercise: Breast Cancer Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's evaulate a model using Scikit-Learn's breast cancer dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=10000, random_state=42)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the data\n",
    "preds, target = load_breast_cancer(return_X_y=True)\n",
    "\n",
    "# Split into train and test\n",
    "X_train, X_test, y_train, y_test = train_test_split(preds, target,\n",
    "                                                   random_state=42)\n",
    "\n",
    "# Scale the data\n",
    "bc_scaler = StandardScaler()\n",
    "bc_scaler.fit(X_train)\n",
    "X_train_sc = bc_scaler.transform(X_train)\n",
    "X_test_sc = bc_scaler.transform(X_test)\n",
    "\n",
    "# Run the model\n",
    "bc_model = LogisticRegression(solver='lbfgs', max_iter=10000,\n",
    "                           random_state=42)\n",
    "bc_model.fit(X_train_sc, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true,
    "hidden": true
   },
   "source": [
    "## Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Calculate the following for this model:\n",
    "\n",
    "- Confusion Matrix\n",
    "- Accuracy\n",
    "- Precision\n",
    "- Recall\n",
    "- F1 Score\n",
    "\n",
    "Discuss: Which one would you choose to evaluate the model for use as a diagnostic tool to detect breast cancer? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bryankeating/miniconda3/envs/learn-env/lib/python3.8/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function plot_confusion_matrix is deprecated; Function `plot_confusion_matrix` is deprecated in 1.0 and will be removed in 1.2. Use one of the class methods: ConfusionMatrixDisplay.from_predictions or ConfusionMatrixDisplay.from_estimator.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Your work here\n",
    "plot_confusion_matrix(bc_model, X_test_sc, y_test);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9790209790209791, 0.9775280898876404, 0.9886363636363636, 0.983050847457627)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tn = 53\n",
    "fp = 1\n",
    "fn = 2\n",
    "tp = 87\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "rec = tp / (tp + fn)\n",
    "prec = tp / (tp + fp)\n",
    "f1 = 2*prec*rec / (prec + rec)\n",
    "\n",
    "acc, rec, prec, f1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "What if our target has more than two classes?\n",
    "\n",
    "**Multiclass classification** problems have more than two possible values for the target. For example, your target would have 10 possible values if you were trying to [classify an image of a hand-written number as a digit from 0 to 9](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "In these cases, we can use the same methods to evaluate our models. Confusion matrices will no longer be 2x2, but will have a number of rows/columns equal to the number of classes. \n",
    "\n",
    "When calculating metrics like precision, we choose one class to be the \"positive\" class, and the rest are assigned to the \"negative\" class. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "An example of comparing multiclass confusion matrices (letter recognition for two different models from [this repo](https://github.com/MrGeislinger/ASLTransalation)):\n",
    "\n",
    "![https://github.com/MrGeislinger/ASLTransalation/blob/main/fingerspelling/paper/images/resnet50_confusionMatrix.png](../images/resnet50_confusionMatrix.png)\n",
    "![https://raw.githubusercontent.com/MrGeislinger/ASLTransalation/main/fingerspelling/paper/images/vgg16_confusionMatrix.png](../images/vgg16_confusionMatrix.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Summary: Which Metric Should I Care About?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Well, it depends.\n",
    "\n",
    "Accuracy:\n",
    "- Pro: Takes into account both false positives and false negatives.\n",
    "- Con: Can be misleadingly high when there is a significant class imbalance. (A lottery-ticket predictor that *always* predicts a loser will be highly accurate.)\n",
    "\n",
    "Recall:\n",
    "- Pro: Highly sensitive to false negatives.\n",
    "- Con: No sensitivity to false positives.\n",
    "\n",
    "Precision:\n",
    "- Pro: Highly sensitive to false positives.\n",
    "- Con: No sensitivity to false negatives.\n",
    "\n",
    "F-1 Score:\n",
    "- Harmonic mean of recall and precision.\n",
    "\n",
    "The nature of your business problem will help you determine which metric matters.\n",
    "\n",
    "Sometimes false positives are much worse than false negatives: Arguably, a model that compares a sample of crime-scene DNA with the DNA in a city's database of its citizens presents one such case. Here a false positive would mean falsely identifying someone as having been present at a crime scene, whereas a false negative would mean only that we fail to identify someone who really was present at the crime scene as such.\n",
    "\n",
    "On the other hand, consider a model that inputs X-ray images and predicts the presence of cancer. Here false negatives are surely worse than false positives: A false positive means only that someone without cancer is misdiagnosed as having it, while a false negative means that someone with cancer is misdiagnosed as *not* having it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Cost Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "One might assign different weights to the costs associated with false positives and false negatives. (We'll standardly assume that the costs associated with *true* positives and negatives are negligible.)\n",
    "\n",
    "**Example**. Suppose we are in the DNA prediction scenario above. Then we might construct the following cost matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "cost = np.array([[0, 10], [3, 0]])\n",
    "cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "This cost matrix will allow us to compare models if we have access to those models' rates of false positives and false negatives, i.e. if we have access to the models' confusion matrices!\n",
    "\n",
    "**Problem**. Given the cost matrix above and the confusion matrices below, which model should we go with?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "conf1, conf2 = np.array([[100, 10], [30, 300]]), np.array([[120, 20], [0, 300]])\n",
    "\n",
    "print(conf1, 2*'\\n', conf2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Level Up: Multiclass Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "flowers = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(flowers.DESCR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "dims_train, dims_test, spec_train, spec_test = train_test_split(flowers.data,\n",
    "                                                                flowers.target,\n",
    "                                                                test_size=0.5,\n",
    "                                                               random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "spec_train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "ss_f = StandardScaler()\n",
    "\n",
    "ss_f.fit(dims_train)\n",
    "\n",
    "dims_train_sc = ss_f.transform(dims_train)\n",
    "dims_test_sc = ss_f.transform(dims_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "logreg_f = LogisticRegression(multi_class='multinomial',\n",
    "                             C=0.01, random_state=42)\n",
    "\n",
    "logreg_f.fit(dims_train_sc, spec_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plot_confusion_matrix(estimator=logreg_f,\n",
    "                      X=dims_test_sc,\n",
    "                      y_true=spec_test,\n",
    "                     display_labels=[\n",
    "                         'setosa',\n",
    "                         'versicolor',\n",
    "                         'virginica'\n",
    "                            ]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(spec_test,\n",
    "              logreg_f.predict(dims_test_sc)))"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "386px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
